"""
SHiFT Code Finder + Streamlit UI

This improved app actively scrapes configured public tracker sites, extracts SHiFT codes
using robust regex parsing, deduplicates them, and presents them as easy-to-copy lists.

Features:
- Built-in tracker list (mentalMars, ShiftCodesTK, Game8, Reddit threads) with ability to add custom tracker URLs.
- Concurrent fetching for faster scans using ThreadPoolExecutor.
- Robust code extraction (handles codes with/without dashes, various separators).
- Shows counts, deduplicated lists for Active / Recently Found codes, and allows CSV export.

Limitations:
- This app scrapes public tracker pages; it does not sign into SHiFT or redeem codes on your behalf.
- Trackers are community-maintained and may contain inaccurate or expired codes.

Author: Generated by ChatGPT
"""

import re
import io
import time
from typing import List, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
from bs4 import BeautifulSoup
import streamlit as st
import pandas as pd

# ---------------------- Configuration ----------------------
REQUEST_TIMEOUT = 12
HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; ShiftFinder/2.0; +https://github.com/yourrepo)",
}

# Seed tracker pages (community lists / news pages)
TRACKERS = [
    "https://mentalmars.com/tag/shift-codes/",
    "https://shiftcodestk.com/",
    "https://game8.co/games/Borderlands-4/archives/",
    "https://www.reddit.com/r/Borderlands/comments/",
]

OFFICIAL_SHIFT_URL = "https://shift.gearboxsoftware.com/"

# Accept many code formats: 25 alnum or 5-5-5-5-5 style
CODE_RE = re.compile(r"[A-Z0-9]{5}(?:[- ]?[A-Z0-9]{5}){4}|[A-Z0-9]{25}", re.IGNORECASE)

# ---------------------- Helpers ----------------------

def normalize_code(s: str) -> str:
    s = s.strip().upper()
    chars = re.sub(r"[^A-Z0-9]", "", s)
    if len(chars) == 25:
        parts = [chars[i:i+5] for i in range(0, 25, 5)]
        return "-".join(parts)
    # If contains dashes already in 5 groups
    m = re.search(r"([A-Z0-9]{5})[- ]?([A-Z0-9]{5})[- ]?([A-Z0-9]{5})[- ]?([A-Z0-9]{5})[- ]?([A-Z0-9]{5})", s)
    if m:
        return "-".join(m.groups())
    return chars


def fetch_page(url: str) -> Tuple[str, str]:
    try:
        r = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
        r.raise_for_status()
        return url, r.text
    except Exception as e:
        return url, ""


def extract_codes_from_html(html: str) -> List[str]:
    if not html:
        return []
    soup = BeautifulSoup(html, "lxml")
    text = soup.get_text(separator=" ")
    found = CODE_RE.findall(text)
    normalized = [normalize_code(f) for f in found]
    # filter out empty
    return [c for c in normalized if c]


def scan_trackers(urls: List[str], max_workers: int = 6) -> Dict[str, List[str]]:
    results = {}
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = {ex.submit(fetch_page, url): url for url in urls}
        for fut in as_completed(futures):
            url = futures[fut]
            try:
                _, html = fut.result()
            except Exception:
                html = ""
            codes = extract_codes_from_html(html)
            results[url] = sorted(set(codes))
            time.sleep(0.1)
    return results

# ---------------------- Streamlit UI ----------------------

def main():
    st.set_page_config(page_title="SHiFT Code Finder", layout="wide")
    st.title("SHiFT Code Finder — Streamlit")

    st.markdown("""
        This app **finds SHiFT codes** by scraping public tracker pages and extracting codes.
        Codes are deduplicated and shown as an easy-to-copy list. Use responsibly.
    """)

    st.sidebar.header("Settings")
    workers = st.sidebar.slider("Concurrent workers", 2, 20, 6)
    add_url = st.sidebar.text_input("Add custom tracker URL")
    seed_urls = st.sidebar.text_area("Tracker URLs (one per line)", value="\n".join(TRACKERS), height=180)

    urls = [u.strip() for u in seed_urls.splitlines() if u.strip()]
    if add_url:
        urls.append(add_url.strip())

    if st.button("Scan trackers now"):
        with st.spinner("Scanning trackers..."):
            scanned = scan_trackers(urls, max_workers=workers)

        # compile master list
        master = set()
        rows = []
        for url, codes in scanned.items():
            for c in codes:
                master.add(c)
                rows.append({"source": url, "code": c})

        df = pd.DataFrame(rows)
        df = df.drop_duplicates().sort_values(by=["code"])

        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader(f"Found codes ({len(master)})")
            st.dataframe(df)

            st.markdown("**Deduplicated list**")
            st.code("\n".join(sorted(master)) or "(none)")

            buf = io.StringIO()
            df.to_csv(buf, index=False)
            st.download_button("Download CSV", buf.getvalue(), file_name="shift_found_codes.csv")

        with col2:
            st.subheader("Tracker summary")
            for url, codes in scanned.items():
                st.markdown(f"- {url} — {len(codes)} codes")

            st.markdown("---")
            st.markdown("**Notes**")
            st.markdown(
                "- This tool collects codes from public tracker pages only.\n- It does NOT redeem codes or sign into SHiFT accounts.\n- Community trackers may contain expired codes."
            )

if __name__ == '__main__':
    main()
